#! /usr/bin/env python2
"""
export trac tickets to GitHub issues
"""
import calendar
import datetime
import json
import os

import argh
from trac2.convert import convert_text
from trac2.github import GitHubAdaptor
from trac2.trac import TracAdaptor


def datetime2epoch(dt):
    """Convert a non-naive datetime object to a UNIX epoch timestamp"""
    if dt is not None:
        return calendar.timegm(dt.utctimetuple())


def toJson(obj):
    if isinstance(obj, datetime.datetime):
        return datetime2epoch(obj)

def parse_config(filename):
    """
    a config reader
    """
    config = dict()

    execfile(filename, dict(), config)

    return config


@argh.arg('--dry-run', action='store_true',
                    help='do not perform any modifications')
@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
def trac2gh(config, dry_run=False):
    github = GitHubAdaptor(config['github'], dry_run)
    all_tickets = {}
    for ticket in TracAdaptor(config['trac'], dry_run).get_tickets():
        data = ticket.as_dict()
        data['description'] = convert_text(data['description'])
        issue, url = github.create_issue(data)
        ticket.mark_exported(issue, url)


@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
@argh.arg('dump_file', metavar='FILE',
                    help='output file name for the json dump')
def trac2json(config, dump_file):
    """ Connect to trac and dump the database as pre-processed intermediate json """
    all_tickets = {}
    for ticket in TracAdaptor(config['trac'], True).get_tickets():
        data = ticket.as_dict()
        data['description'] = convert_text(data['description'])
        all_tickets[data['id']] = data
        j = json.dumps(all_tickets, default=toJson, indent=2)
        with open(dump_file, 'w') as f:
            f.write(j)

@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
@argh.arg('dump_file', metavar='FILE',
                    help='input file name for the json dump')
def build_user_mapping(config, dump_file):
    """ Build the user mapping from trac to github """

    with open(dump_file, 'r') as f:
        all_tickets = json.load(f)
    trac = TracAdaptor(config['trac'], True)
    active_users = {}
    id2emails = trac._users
    emails2id = { v:k for k, v in id2emails.items()}
    emails2id.update({ k:k for k, v in id2emails.items()})
    for ticket in all_tickets.values():
        for c in ticket['contributors'].keys():
            if c in emails2id:
                active_users.setdefault(emails2id[c], {"email": c, "activities": 0})
                active_users[emails2id[c]]['activities'] += 1

    print len(active_users), "active users"

    github = GitHubAdaptor(config['github'], True)
    not_mapped_users = {}
    for k, v in active_users.items():
        ret = github.find_user_in_commits(v['email'])
        if ret is None:
            not_mapped_users[v['email']] = v

    still_not_mapped_users = github.find_users(not_mapped_users.keys())

    print "unable to find mapping for following users"
    still_not_mapped_users = sorted(
        [ (not_mapped_users[email]['activities'], email) for email in still_not_mapped_users ])
    for activities, email in still_not_mapped_users:
        print activities, email


@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
@argh.arg('dump_file', metavar='FILE',
                    help='input file name for the json dump')
def json2gh(config, dump_file, update_ticket=False, mention_people=False):
    """ Connect to github and create the issues from the pre-processed intermediate json """
    trac = TracAdaptor(config['trac'], False)
    github = GitHubAdaptor(config['github'], False, only_from_cache=True, mention_people=mention_people)
    with open(dump_file, 'r') as f:
        all_tickets = json.load(f)
    for ticket in sorted(all_tickets.values(), key=lambda x: x['time'])[26:]:
        issue, url = github.create_issue(ticket)
        print url
        if update_ticket:
            trac.ticket(ticket).mark_exported(issue, url)


@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
@argh.arg('dump_file', metavar='FILE',
                    help='output file name for the json dump')
def wiki_trac2json(config, dump_file):
    """ Connect to trac and dump the database as pre-processed intermediate json """
    all_wikis = {}
    for wikipage in TracAdaptor(config['trac'], True).get_wikipages():
        data = wikipage.as_dict()
        data['text'] = convert_text(data['text'])
        all_wikis[data['name']] = data
        j = json.dumps(all_wikis, default=toJson, indent=2)
        with open(dump_file, 'w') as f:
            f.write(j)

@argh.arg('config', metavar='FILE', type=parse_config,
                    help='configuration file for the migration')
@argh.arg('dump_file', metavar='FILE',
                    help='input file name for the json dump')
def wiki_json2dir(config, dump_file, output_dir):
    """ Connect to github and create the issues from the pre-processed intermediate json """
    with open(dump_file, 'r') as f:
        all_tickets = json.load(f)
    for ticket in all_tickets.values():
        output_file = os.path.join(output_dir, ticket['name'] + ".md")
        os.system("mkdir -p " + os.path.dirname(output_file))
        with open(output_file, "w") as f:
            f.write(ticket['text'].encode("utf8"))


parser = argh.ArghParser()
parser.add_commands([trac2gh, trac2json, build_user_mapping, json2gh, wiki_trac2json, wiki_json2dir])

# dispatching:
if __name__ == '__main__':
    parser.dispatch()
